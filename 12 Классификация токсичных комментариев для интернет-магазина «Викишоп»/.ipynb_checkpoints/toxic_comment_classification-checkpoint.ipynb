{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/akhmetshin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/akhmetshin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/akhmetshin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортирование данных из файла\n",
    "data = pd.read_csv(\"datasets/toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143106\n",
      "1     16186\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим сколько у нас токсичных/нетоксичных текстов\n",
    "print(data['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процентное соотношение токсичных комментариев ко всем: 10.16%\n"
     ]
    }
   ],
   "source": [
    "toxic_percentage = (data['toxic'].sum() / len(data)) * 100\n",
    "print(f\"Процентное соотношение токсичных комментариев ко всем: {toxic_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведем данные к нижнему регистру, а также удалим лишние символы и знаки препинания из текста комментариев:\n",
    "def preprocessor(text):\n",
    "    text = re.sub(r'[^\\w\\s]','', text.lower())\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "data['lemmatized_text'] = data['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(x) if w not in stop_words]))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>КОММЕНТАРИЙ СТУДЕНТА 2:</b><br>\n",
    "    <b>Вывод:</b>\n",
    "    \n",
    "- Импортированы основные библиотеки\n",
    "- Загружены данные toxic_comments.csv\n",
    "- Вычислено процентное соотношение токсичных комментариев: 10.16%\n",
    "- Определена функция preprocessor, которая применяется к полю 'text' для предобработки текста, включающей удаление знаков препинания и приведение к нижнему регистру\n",
    "- Выполнена лемматизация текстового столбца 'text'. Результат лемматизации сохраняется в новом столбце 'lemmatized_text'\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['lemmatized_text'], data['toxic'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели логистической регрессии: {'lr__C': 1.0, 'lr__penalty': 'l2', 'tfidf__ngram_range': (1, 1)}\n",
      "F1-мера на кросс-валидации: 0.7\n"
     ]
    }
   ],
   "source": [
    "model_lr = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer()),\n",
    "    ('tfidf', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', stop_words=stop_words)),\n",
    "    ('lr', LogisticRegression(max_iter=10000, solver='saga', random_state=42))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'lr__C': np.logspace(-3, 0, 4),\n",
    "    'lr__penalty': ['l2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_lr, parameters, cv=2, scoring='f1', n_jobs=-1, verbose=0)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_f1_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Лучшие параметры для модели логистической регрессии:\", best_params)\n",
    "print(\"F1-мера на кросс-валидации:\", round(best_f1_score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] END svm__C=0.001, svm__kernel=linear, tfidf__ngram_range=(1, 1); total time= 6.4min\n",
      "[CV] END svm__C=0.001, svm__kernel=linear, tfidf__ngram_range=(1, 1); total time= 6.6min\n",
      "[CV] END svm__C=0.01, svm__kernel=linear, tfidf__ngram_range=(1, 1); total time= 7.8min\n",
      "[CV] END svm__C=0.01, svm__kernel=linear, tfidf__ngram_range=(1, 1); total time= 7.9min\n",
      "Лучшие параметры для модели метода опорных векторов: {'svm__C': 0.01, 'svm__kernel': 'linear', 'tfidf__ngram_range': (1, 1)}\n",
      "F1-мера на валидации для модели метода опорных векторов: 0.24\n"
     ]
    }
   ],
   "source": [
    "model_svm = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer()),\n",
    "    ('tfidf', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', stop_words=stop_words)),\n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "'tfidf__ngram_range': [(1, 1)],\n",
    "'svm__C': np.logspace(-3, -2, 2),\n",
    "'svm__kernel': ['linear']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_svm, parameters, cv=2, scoring='f1', n_jobs=-1, verbose=2, pre_dispatch=10)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Лучшие параметры для модели метода опорных векторов:\", best_params)\n",
    "\n",
    "f1_svm_val = grid_search.best_score_\n",
    "\n",
    "print(\"F1-мера на валидации для модели метода опорных векторов:\", round(f1_svm_val,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели случайного леса: {'rf__max_depth': None, 'tfidf__max_features': 5000}\n",
      "Лучшее значение метрики F1 на кросс-валидации для модели случайного леса: 0.74\n"
     ]
    }
   ],
   "source": [
    "model_rf = Pipeline([\n",
    "('tfidf', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', stop_words=stop_words)),\n",
    "('rf', RandomForestClassifier(n_estimators=50, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "'tfidf__max_features': [1000, 5000],\n",
    "'rf__max_depth': [10, 20, None],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_rf, param_grid=param_grid, cv=4, scoring='f1', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Лучшие параметры для модели случайного леса:\", best_params)\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Лучшее значение метрики F1 на кросс-валидации для модели случайного леса:\", round(best_score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики F1 на тестовой выборке для модели случайного леса: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Создаем модель случайного леса с лучшими параметрами\n",
    "best_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', stop_words=stop_words, max_features=5000)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, max_depth=None, random_state=42))\n",
    "])\n",
    "\n",
    "# Обучаем модель на тренировочных данных\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Получаем предсказания на тестовой выборке\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Вычисляем метрику F1 на тестовой выборке\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Выводим значение метрики F1 на тестовой выборке\n",
    "print(\"Значение метрики F1 на тестовой выборке для модели случайного леса:\", round(f1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>КОММЕНТАРИЙ СТУДЕНТА 1:</b><br>\n",
    "    <b>Вывод:</b>\n",
    "    \n",
    "- Данные разбиты на обучающую и тестовую выборки с соотношением 80:20\n",
    "- Лучшие параметры для модели логистической регрессии: {'lr__C': 1.0, 'lr__penalty': 'l2', 'tfidf__ngram_range': (1, 1)}\n",
    "- F1-мера на кросс-валидации: 0.7     \n",
    "- Лучшие параметры для модели метода опорных векторов: {'svm__C': 0.01, 'svm__kernel': 'linear', 'tfidf__ngram_range': (1, 1)}\n",
    "- F1-мера на валидации для модели метода опорных векторов: 0.24\n",
    "- Лучшие параметры для модели случайного леса: {'rf__max_depth': None, 'tfidf__max_features': 5000}\n",
    "- Лучшее значение метрики F1 на кросс-валидации для модели случайного леса: 0.74\n",
    "- Модель случайного леса имеет наилучшее качество с F1-мерой равной 0.74, тогда как логистическая регрессия и модель метода опорных векторов имеют F1-меру 0.7 и 0.24 соответственно\n",
    "- Значение метрики F1 на тестовой выборке для модели случайного леса: 0.75\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>КОММЕНТАРИЙ СТУДЕНТА 1:</b><br>\n",
    "    <b>Общий вывод:</b>\n",
    "    \n",
    "- Подготовка:\n",
    "            \n",
    "    - Импортированы основные библиотеки\n",
    "    - Загружены данные toxic_comments.csv\n",
    "    - Вычислено процентное соотношение токсичных комментариев: 10.16% \n",
    "    - Определена функция preprocessor, которая применяется к полю 'text' для предобработки текста, включающей удаление знаков препинания и приведение к нижнему регистру\n",
    "    - Выполнена лемматизация текстового столбца 'text'. Результат лемматизации сохраняется в новом столбце 'lemmatized_text'\n",
    "        \n",
    "- Обучение:\n",
    "            \n",
    "    - Данные разбиты на обучающую и тестовую выборки с соотношением 80:20\n",
    "    - F1-мера для модели логистической регрессии: 0.77\n",
    "    - Лучшие параметры для модели логистической регрессии: {'lr__C': 1.0, 'lr__penalty': 'l2', 'tfidf__ngram_range': (1, 1)}\n",
    "    - F1-мера для модели метода опорных векторов: 0.34\n",
    "    - Лучшие параметры для модели метода опорных векторов: {'svm__C': 0.01, 'svm__kernel': 'linear', 'tfidf__ngram_range': (1, 1)}\n",
    "    - F1-мера для модели случайного леса: 0.99\n",
    "    - Лучшие параметры для модели случайного леса: {'rf__max_depth': None, 'tfidf__max_features': 5000}\n",
    "    - Модель случайного леса имеет наилучшее качество с F1-мерой равной 0.99, тогда как логистическая регрессия и модель метода опорных векторов имеют F1-меру 0.77 и 0.34 соответственно.\n",
    "    - F1-мера для модели случайного леса на тестовой выборке: 0.76\n",
    "     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1083,
    "start_time": "2023-05-04T13:53:36.455Z"
   },
   {
    "duration": 124,
    "start_time": "2023-05-04T13:53:37.540Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-04T13:53:37.666Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-04T13:53:37.667Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-04T13:53:37.668Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-04T13:53:37.669Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-04T13:53:37.669Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-04T13:53:37.672Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-04T13:53:37.673Z"
   },
   {
    "duration": 1095,
    "start_time": "2023-05-04T13:53:57.441Z"
   },
   {
    "duration": 2290,
    "start_time": "2023-05-04T13:53:58.538Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-04T13:54:00.829Z"
   },
   {
    "duration": 36,
    "start_time": "2023-05-04T13:54:00.837Z"
   },
   {
    "duration": 1580,
    "start_time": "2023-05-04T13:54:00.874Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-04T13:54:02.456Z"
   },
   {
    "duration": 57582,
    "start_time": "2023-05-04T13:54:02.478Z"
   },
   {
    "duration": 8362,
    "start_time": "2023-05-04T13:55:00.062Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
